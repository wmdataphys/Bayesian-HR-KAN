{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Equation\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} - q(x,y) = 0,\n",
    "\\end{equation}\n",
    "with the forcing term:\n",
    "\\begin{equation}\n",
    "q(x,y) = -2\\pi^2 \\sin(\\pi x) \\sin(\\pi y)\n",
    "\\end{equation}\n",
    "The analytical solution:\n",
    "\\begin{equation}\n",
    "u(x,y) = \\sin(\\pi x) \\sin(\\pi y)\n",
    "\\end{equation}\n",
    "\n",
    "With boundary conditions:\n",
    "\\begin{equation}\n",
    "u(-1,y) = u(1,y) = u(x,-1) = u(x,1) = 0.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Library and Generate train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.torch_relukan import ReLUKANLayer, ReLUKAN\n",
    "from models.torch_hrkan import HRKANLayer, HRKAN\n",
    "from models.Bayes_ReLUKAN import Bayes_ReLUKAN\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import autograd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pkbar\n",
    "from loss_utils import Gaussian_likelihood\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.001\n",
    "dim = 2\n",
    "np_i = 64\n",
    "np_b = 64 \n",
    "ranges = [-1, 1]\n",
    "sigma=0.1\n",
    "### We will need to do a call to this function in each cell to continually set the seeds in a notebook\n",
    "# we will only do it for the aleatoric training\n",
    "def set_seeds_(seed=752022):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "def batch_jacobian(func, x, create_graph=False):\n",
    "    def _func_sum(x):\n",
    "        return func(x).sum(dim=0)\n",
    "    return autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "\n",
    "def batch_jacobian_aleatoric(func, x, create_graph=False, first_call=False):\n",
    "    def _func_sum_y(x):\n",
    "        y, _ = func(x)\n",
    "        return y.sum(dim=0)\n",
    "    y, alea = func(x)\n",
    "    y_jacobian = autograd.functional.jacobian(_func_sum_y, x, create_graph=create_graph)\n",
    "    \n",
    "    if first_call:\n",
    "        return y_jacobian.permute(1, 0, 2)[:, 0, :], alea\n",
    "    else:\n",
    "        return y_jacobian.permute(1, 0, 2)[:,:,:], alea\n",
    "\n",
    "# define solution\n",
    "sol_fun = lambda x: torch.sin(torch.pi*x[:,[0]])*torch.sin(torch.pi*x[:,[1]]) + torch.abs(x[:,[0]])*torch.tensor(np.random.normal(loc=0,scale=sigma,size=x[:,[0]].shape),device=x.device)\n",
    "source_fun = lambda x: -2*torch.pi**2 * torch.sin(torch.pi*x[:,[0]])*torch.sin(torch.pi*x[:,[1]]) + torch.abs(x[:,[0]])*torch.tensor(np.random.normal(loc=0,scale=sigma,size=x[:,[0]].shape),device=x.device)\n",
    "noise_fun = lambda x: torch.abs(x[:,[0]])*torch.tensor(np.random.normal(loc=0,scale=sigma,size=x[:,[0]].shape),device=x.device)\n",
    "\n",
    "# interior\n",
    "sampling_mode = 'random'\n",
    "\n",
    "x_mesh = torch.linspace(ranges[0],ranges[1],steps=np_i)\n",
    "y_mesh = torch.linspace(ranges[0],ranges[1],steps=np_i)\n",
    "X, Y = torch.meshgrid(x_mesh, y_mesh, indexing=\"ij\")\n",
    "if sampling_mode == 'mesh':\n",
    "    #mesh\n",
    "    x_i = torch.stack([X.reshape(-1,), Y.reshape(-1,)]).permute(1,0)\n",
    "else:\n",
    "    #random\n",
    "    x_i = torch.rand((np_i**2,2))*2-1\n",
    "\n",
    "# boundary, 4 sides\n",
    "helper = lambda X, Y: torch.stack([X.reshape(-1,), Y.reshape(-1,)]).permute(1,0)\n",
    "xb1 = helper(X[0], Y[0])\n",
    "xb2 = helper(X[-1], Y[0])\n",
    "xb3 = helper(X[:,0], Y[:,0])\n",
    "xb4 = helper(X[:,0], Y[:,-1])\n",
    "x_b = torch.cat([xb1, xb2, xb3, xb4], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "sampling_mode_test = 'mesh'\n",
    "\n",
    "x_test_mesh = torch.linspace(ranges[0],ranges[1],steps=100)\n",
    "y_test_mesh = torch.linspace(ranges[0],ranges[1],steps=100)\n",
    "X_test, Y_test = torch.meshgrid(x_test_mesh, y_test_mesh, indexing=\"ij\")\n",
    "if sampling_mode == 'mesh':\n",
    "    #mesh\n",
    "    x_test_i = torch.stack([X_test.reshape(-1,), Y_test.reshape(-1,)]).permute(1,0)\n",
    "else:\n",
    "    #random\n",
    "    x_test_i = torch.rand((np_i**2,2))*2-1\n",
    "    \n",
    "xb1_test = helper(X_test[0], Y_test[0])\n",
    "xb2_test = helper(X_test[-1], Y_test[0])\n",
    "xb3_test = helper(X_test[:,0], Y_test[:,0])\n",
    "xb4_test = helper(X_test[:,0], Y_test[:,-1])\n",
    "x_test_b = torch.cat([xb1_test, xb2_test, xb3_test, xb4_test], dim=0)\n",
    "\n",
    "X_test_np = X_test.clone().detach().numpy()\n",
    "Y_test_np = Y_test.clone().detach().numpy()\n",
    "x_test = torch.stack([X_test.reshape(-1,), Y_test.reshape(-1,)]).permute(1,0)\n",
    "sol = sol_fun(x_test)\n",
    "noise_f = noise_fun(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(X_test_np,Y_test_np,sol.reshape(X_test_np.shape),shading='auto',cmap='seismic')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check if have GPU and move data there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x_i = x_i.cuda()\n",
    "    x_b = x_b.cuda()\n",
    "    x_test = x_test.cuda()\n",
    "    x_test_i = x_test_i.cuda()\n",
    "    x_test_b = x_test_b.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function to Train Bayesian (H)ReLU-KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "def train_bkan(model,num_epochs):\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    plt.ion()\n",
    "    losses = []\n",
    "    pde_losses = []\n",
    "    bc_losses = []\n",
    "    pde_losses_test = []\n",
    "    bc_losses_test = []\n",
    "    l2_losses_test = []\n",
    "    l2_losses_std_test= []\n",
    "\n",
    "    start = time.time()\n",
    "    epoch = 0\n",
    "    alpha=1.0\n",
    "    kbar = pkbar.Kbar(target=num_epochs, epoch=epoch, num_epochs=num_epochs, width=20, always_stateful=False)\n",
    "    for epoch in range(num_epochs):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        sol_D1_fun = lambda x: batch_jacobian_aleatoric(model, x, create_graph=True,first_call=True)\n",
    "        sol_D2,sigma_D2 = batch_jacobian_aleatoric(sol_D1_fun, x_i, create_graph=True)\n",
    "        lap = torch.sum(torch.diagonal(sol_D2, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "        source = source_fun(x_i)\n",
    "        pde_loss,pde_mse = Gaussian_likelihood(lap,sigma_D2,source)\n",
    "\n",
    "        bc_true = sol_fun(x_b)\n",
    "        bc_pred,bc_log_devs2 = model(x_b)\n",
    "        bc_loss,bc_mse = Gaussian_likelihood(bc_pred,bc_log_devs2,bc_true)\n",
    "     \n",
    "\n",
    "        kl_div_ = beta * model.kl_div()\n",
    "        pde = alpha * pde_loss\n",
    "        loss = pde + bc_loss + kl_div_\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sol_D2_test,sigma_D2_test = batch_jacobian_aleatoric(sol_D1_fun, x_test_i, create_graph=False)\n",
    "            lap_test = torch.sum(torch.diagonal(sol_D2_test, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "            source_test = source_fun(x_test_i)\n",
    "            pde_loss_test,test_pde_mse = Gaussian_likelihood(lap_test,sigma_D2_test,source_test)\n",
    "    \n",
    "            bc_true_test = sol_fun(x_test_b)\n",
    "            bc_pred_test,bc_logdevs2_test = model(x_test_b)\n",
    "            bc_loss_test,test_bc_mse = Gaussian_likelihood(bc_pred_test,bc_logdevs2_test,bc_true_test)\n",
    "    \n",
    "            l2_test = torch.mean((model(x_test)[0].cpu() - sol)**2)\n",
    "            l2_test_std = torch.std((model(x_test)[0].cpu() - sol)**2)\n",
    "\n",
    "            test_kl_ = beta * model.kl_div()\n",
    "            test_loss_ = alpha * pde_loss_test + bc_loss_test + test_kl_\n",
    "\n",
    "                \n",
    "\n",
    "            pde_losses.append(pde_loss.cpu().detach().numpy())\n",
    "            bc_losses.append(bc_loss.cpu().detach().numpy())\n",
    "            pde_losses_test.append(pde_loss_test.cpu().detach().numpy())\n",
    "            bc_losses_test.append(bc_loss_test.cpu().detach().numpy())\n",
    "            l2_losses_test.append(l2_test.cpu().detach().numpy())\n",
    "            l2_losses_std_test.append(l2_test_std.cpu().detach().numpy())\n",
    "\n",
    "        kbar.update(epoch,values=[(\"loss\", loss.item()),('mse',pde_mse.item()),(\"kl_div\",kl_div_.item()),(\"pde\",pde.item()),(\"bc\",bc_loss.item()),(\"test_loss\",test_loss_.item())])\n",
    "\n",
    "    elapsed = (time.time() - start)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output,epistemic,aleatoric_ = model.sample(x_test,num_samples=5000)\n",
    "        output = output.cpu().clone().detach().numpy().reshape(X_test_np.shape)\n",
    "        epistemic = epistemic.cpu().clone().detach().numpy().reshape(X_test_np.shape)\n",
    "        aleatoric_ = aleatoric_.cpu().clone().detach().numpy().reshape(X_test_np.shape)\n",
    "\n",
    "    return output, losses, pde_losses, bc_losses, pde_losses_test, bc_losses_test, l2_losses_test, l2_losses_std_test, elapsed,epistemic,aleatoric_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the function to train ReLUKAN and HRKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "def train_model(model,num_epochs):\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    plt.ion()\n",
    "    losses = []\n",
    "    pde_losses = []\n",
    "    bc_losses = []\n",
    "    pde_losses_test = []\n",
    "    bc_losses_test = []\n",
    "    l2_losses_test = []\n",
    "    l2_losses_std_test= []\n",
    "\n",
    "    start = time.time()\n",
    "    epoch = 0\n",
    "    kbar = pkbar.Kbar(target=num_epochs, epoch=epoch, num_epochs=num_epochs, width=20, always_stateful=False)\n",
    "    for epoch in range(num_epochs):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        sol_D1_fun = lambda x: batch_jacobian(model, x, create_graph=True)[:,0,:]\n",
    "        sol_D2 = batch_jacobian(sol_D1_fun, x_i, create_graph=True)[:,:,:]\n",
    "        lap = torch.sum(torch.diagonal(sol_D2, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "        source = source_fun(x_i)\n",
    "        pde_loss = torch.mean((lap - source)**2)\n",
    "\n",
    "        bc_true = sol_fun(x_b)\n",
    "        bc_pred = model(x_b)\n",
    "        bc_loss = torch.mean((bc_pred-bc_true)**2)\n",
    "\n",
    "        loss = alpha * pde_loss + bc_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            sol_D2_test = batch_jacobian(sol_D1_fun, x_test_i, create_graph=False)[:,:,:]\n",
    "            lap_test = torch.sum(torch.diagonal(sol_D2_test, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "            source_test = source_fun(x_test_i)\n",
    "            pde_loss_test = torch.mean((lap_test - source_test)**2)\n",
    "    \n",
    "            bc_true_test = sol_fun(x_test_b)\n",
    "            bc_pred_test = model(x_test_b)\n",
    "            bc_loss_test = torch.mean((bc_pred_test-bc_true_test)**2)\n",
    "    \n",
    "            l2_test = torch.mean((model(x_test).cpu() - sol)**2)\n",
    "            l2_test_std = torch.std((model(x_test).cpu() - sol)**2)\n",
    "    \n",
    "            pde_losses.append(pde_loss.cpu().detach().numpy())\n",
    "            bc_losses.append(bc_loss.cpu().detach().numpy())\n",
    "            pde_losses_test.append(pde_loss_test.cpu().detach().numpy())\n",
    "            bc_losses_test.append(bc_loss_test.cpu().detach().numpy())\n",
    "            l2_losses_test.append(l2_test.cpu().detach().numpy())\n",
    "            l2_losses_std_test.append(l2_test_std.cpu().detach().numpy())\n",
    "\n",
    "        kbar.update(epoch,values=[(\"loss\", loss.item())])\n",
    "\n",
    "    elapsed = (time.time() - start)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(x_test).cpu().clone().detach().numpy().reshape(X_test_np.shape)\n",
    "    \n",
    "    return output, losses, pde_losses, bc_losses, pde_losses_test, bc_losses_test, l2_losses_test, l2_losses_std_test, elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define the function to plot ground-truth solution, learnt solutions and their residual difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "def plot_fig(relu_kan_, hrkan_, bkan_, output_folder='PDE'):\n",
    "    label_size = 25\n",
    "    labelpad = 15\n",
    "    tick_size2 = 18\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(26, 13), subplot_kw={\"projection\": \"3d\"})\n",
    "    fig.delaxes(axs[1, 0])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # true solution\n",
    "    surf1 = axs[0, 0].plot_surface(X_test_np, Y_test_np, sol.reshape(X_test_np.shape), cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[0, 0].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[0, 0].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 0].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 0].set_title('Ground-truth + Noise', fontsize=label_size)\n",
    "    \n",
    "    # RELU_KAN\n",
    "    surf2 = axs[0, 1].plot_surface(X_test_np, Y_test_np, relu_kan_[0], cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[0, 1].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[0, 1].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 1].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 1].set_title('ReLU-KAN Solution', fontsize=label_size)\n",
    "    \n",
    "    surf3 = axs[1, 1].plot_surface(X_test_np, Y_test_np, (sol.reshape(X_test_np.shape) - relu_kan_[0]), cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[1, 1].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[1, 1].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 1].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 1].set_title('ReLU-KAN Residual', fontsize=label_size)\n",
    "    \n",
    "    # HRKAN\n",
    "    surf4 = axs[0, 2].plot_surface(X_test_np, Y_test_np, hrkan_[0], cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[0, 2].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[0, 2].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 2].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 2].set_title('HRKAN Solution', fontsize=label_size)\n",
    "    \n",
    "    surf5 = axs[1, 2].plot_surface(X_test_np, Y_test_np, (sol.reshape(X_test_np.shape) - hrkan_[0]), cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[1, 2].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[1, 2].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 2].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 2].set_title('HRKAN Residual', fontsize=label_size)\n",
    "    \n",
    "    # KAN\n",
    "    surf6 = axs[0, 3].plot_surface(X_test_np, Y_test_np, bkan_[0], cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[0, 3].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[0, 3].zaxis.set_major_formatter('{x:.01f}')\n",
    "    axs[0, 3].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 3].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 3].set_zlabel('u(x,y)', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[0, 3].set_title('Bayes-HRKAN Solution', fontsize=label_size)\n",
    "    \n",
    "    surf7 = axs[1, 3].plot_surface(X_test_np, Y_test_np, (sol.reshape(X_test_np.shape) - bkan_[0]), cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "    axs[1, 3].set_zticks([-1.0,-0.5,0,0.5,1.0])\n",
    "    axs[1, 3].zaxis.set_major_formatter('{x:.01f}')\n",
    "    axs[1, 3].set_xlabel('x', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 3].set_ylabel('y', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 3].set_zlabel('u(x,y)', fontsize=label_size,labelpad=labelpad)\n",
    "    axs[1, 3].set_title('Bayes-HRKAN Residual', fontsize=label_size)\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14,pad=0)  # Adjust for x and y axes\n",
    "        ax.tick_params(axis='z', which='major', labelsize=14,pad=9)     # Adjust for z axis (if 3D)\n",
    "\n",
    "\n",
    "    for k in range(4):  # Assuming 4 subplots per row\n",
    "        if k < 3:  # For all but the last subplot in the row\n",
    "            axs[0, k].tick_params(axis='z', labelleft=False)  # Hide z-axis labels in the first row\n",
    "            axs[1, k].tick_params(axis='z', labelleft=False) \n",
    "        \n",
    "    plt.subplots_adjust(hspace=0.0)\n",
    "    cb1 = fig.colorbar(surf1, ax=axs, orientation='vertical')\n",
    "    cb1.ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb1.ax.tick_params(labelsize=20)\n",
    "    plt.savefig(os.path.join(output_folder, 'Poisson_fig.pdf'), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Second figure\n",
    "    fig = plt.figure(figsize=(25, 6))\n",
    "    ax1 = fig.add_subplot(141)#, projection='3d')\n",
    "    ax2 = fig.add_subplot(142)#, projection='3d')\n",
    "    ax3 = fig.add_subplot(143)#, projection='3d')\n",
    "    ax4 = fig.add_subplot(144)\n",
    "\n",
    "    max_ = np.max(np.abs(sol.reshape(X_test_np.shape) - bkan_[0]).cpu().numpy())\n",
    "    \n",
    "    # Plot first surface\n",
    "    surf_epi = ax1.pcolormesh(X_test_np, Y_test_np, bkan_[-2], shading='auto', cmap='seismic')\n",
    "    surf_epi.set_clim(0,max_)\n",
    "    ax1.set_xticks([-1.0, -0.5, 0, 0.5, 1.0])\n",
    "    ax1.set_yticks([-1.0, -0.5, 0, 0.5, 1.0])\n",
    "    ax1.set_xlabel('x', fontsize=label_size, labelpad=labelpad-12)\n",
    "    ax1.set_ylabel('y', fontsize=label_size, labelpad=labelpad-5)\n",
    "    ax1.set_title('Bayes-HRKAN Epistemic', fontsize=label_size)\n",
    "    \n",
    "    # Create colorbar for the first subplot\n",
    "    cb1_ax = fig.add_axes([0.13, -0.03, 0.16, 0.02])  # [left, bottom, width, height]\n",
    "    cb2 = fig.colorbar(surf_epi, cax=cb1_ax, orientation='horizontal')\n",
    "    cb2.ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb2.ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb2.ax.tick_params(labelsize=20)\n",
    "    cb2.set_label('Epistemic Uncertainty', fontsize=label_size,labelpad=10)\n",
    "    \n",
    "\n",
    "    # Plot second surface\n",
    "    surf_alea = ax2.pcolormesh(X_test_np,Y_test_np,bkan_[-1],shading='auto',cmap='seismic')\n",
    "    surf_alea.set_clim(0,max_)\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel('x', fontsize=label_size, labelpad=labelpad-12)\n",
    "    #ax2.set_ylabel('y', fontsize=label_size, labelpad=labelpad-5)\n",
    "    ax2.set_title('Bayes-HRKAN Aleatoric', fontsize=label_size)\n",
    "    \n",
    "    # Create colorbar for the first subplot\n",
    "    cb2_ax = fig.add_axes([0.332, -0.03, 0.16, 0.02])\n",
    "    cb3 = fig.colorbar(surf_alea, cax=cb2_ax, orientation='horizontal')\n",
    "    cb3.ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb3.ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb3.ax.tick_params(labelsize=20)\n",
    "    cb3.set_label('Aleatoric Uncertainty', fontsize=label_size,labelpad=10)\n",
    "    \n",
    "    # Plot third surface\n",
    "    surf_abs = ax3.pcolormesh(X_test_np,Y_test_np,np.abs(sol.reshape(X_test_np.shape) - bkan_[0]),shading='auto',cmap='seismic')\n",
    "    surf_abs.set_clim(0,max_)\n",
    "    ax3.set_yticks([])\n",
    "    ax3.set_xlabel('x', fontsize=label_size, labelpad=labelpad-12)\n",
    "    ax3.set_title('Bayes-HRKAN Absolute Error', fontsize=label_size)\n",
    "    \n",
    "    # Create colorbar for the second subplot\n",
    "    cb3_ax = fig.add_axes([0.535, -0.03, 0.16, 0.02])\n",
    "    cb4 = fig.colorbar(surf_abs, cax=cb3_ax, orientation='horizontal')\n",
    "    cb4.ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb4.ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb4.ax.tick_params(labelsize=20)\n",
    "    cb4.set_label('Absolute Error', fontsize=label_size,labelpad=10)\n",
    "\n",
    "\n",
    "    f = noise_fun(x_test.clone().detach().cpu()).reshape(X_test_np.shape)\n",
    "    # Plot noise\n",
    "    surf_noise = ax4.pcolormesh(X_test_np,Y_test_np,np.abs(f),shading='auto',cmap='seismic')\n",
    "    surf_noise.set_clim(0,max_)\n",
    "    ax4.set_yticks([])\n",
    "    ax4.set_xlabel('x', fontsize=label_size, labelpad=labelpad-12)\n",
    "    ax4.set_title('True Aleatoric Component', fontsize=label_size)\n",
    "    \n",
    "    # Create colorbar for the second subplot\n",
    "    cb4_ax = fig.add_axes([0.738, -0.03, 0.16, 0.02])\n",
    "    cb5 = fig.colorbar(surf_noise, cax=cb4_ax, orientation='horizontal')\n",
    "    cb5.ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb5.ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    cb5.ax.tick_params(labelsize=20)\n",
    "    cb5.set_label('Aleatoric Component', fontsize=label_size,labelpad=10)\n",
    "\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=tick_size2)\n",
    "    ax2.tick_params(axis='x', which='major', labelsize=tick_size2)\n",
    "    ax3.tick_params(axis='x', which='major', labelsize=tick_size2)\n",
    "    ax4.tick_params(axis='x',which='major',labelsize=tick_size2)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.2)  # Adjust the spacing as needed\n",
    "    plt.savefig(os.path.join(output_folder, 'Poisson_epistemic.pdf'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the function to calculate MSE, MSE std. and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "def cal_error(relu_kan_, hrkan_,bkan_):\n",
    "    relu_kan_loss.append([alpha * x + y for x, y in zip(relu_kan_[2], relu_kan_[3])])\n",
    "    relu_kan_loss_test.append([alpha * x + y for x, y in zip(relu_kan_[4], relu_kan_[5])])\n",
    "    relu_kan_L2s.append(relu_kan_[-3])\n",
    "    relu_kan_L2s_std.append(relu_kan_[-2])\n",
    "    relu_kan_time.append(relu_kan_[-1])\n",
    "    hrkan_loss.append([alpha * x + y for x, y in zip(hrkan_[2], hrkan_[3])])\n",
    "    hrkan_loss_test.append([alpha * x + y for x, y in zip(hrkan_[4], hrkan_[5])])\n",
    "    hrkan_L2s.append(hrkan_[-3])\n",
    "    hrkan_L2s_std.append(hrkan_[-2])\n",
    "    hrkan_time.append(hrkan_[-1])\n",
    "    bkan_loss.append([ x + y for x, y in zip(bkan_[2], bkan_[3])])\n",
    "    bkan_loss_test.append([ x + y for x, y in zip(bkan_[4], bkan_[5])])\n",
    "    bkan_L2s.append(bkan_[-5])\n",
    "    bkan_L2s_std.append(bkan_[-4])\n",
    "    bkan_time.append(bkan_[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting seeds\")\n",
    "set_seeds_()\n",
    "\n",
    "relu_kan_preds = []\n",
    "hrkan_preds = []\n",
    "bkan_preds = []\n",
    "relu_kan_loss, relu_kan_loss_test, relu_kan_L2s, relu_kan_L2s_std, relu_kan_time = [], [], [], [], []\n",
    "hrkan_loss, hrkan_loss_test, hrkan_L2s, hrkan_L2s_std, hrkan_time = [], [], [], [], []\n",
    "bkan_loss, bkan_loss_test, bkan_L2s, bkan_L2s_std, bkan_time = [], [], [], [], []\n",
    "\n",
    "num_epochs_bkan=60000\n",
    "num_epochs = 60000\n",
    "output_folder = \"Poisson_Results\"\n",
    "iters = 1\n",
    "\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    print(\" \")\n",
    "    print(\"Outputs will be placed in \" + str(output_folder))\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bkan = Bayes_ReLUKAN([2,2,1], 5, 3, imin=-1, imax=1,aleatoric=True,multi_dim=True,order=4)\n",
    "bkan = bkan.cuda()\n",
    "bkan_results = train_bkan(bkan,num_epochs_bkan)\n",
    "torch.cuda.empty_cache() \n",
    "bkan_preds.append(bkan_results[0])\n",
    "del bkan\n",
    "\n",
    "print(\" \")\n",
    "relu_kan = ReLUKAN([2,2,1], 5, 3, -1, 1)\n",
    "relu_kan = relu_kan.cuda()\n",
    "relu_kan_results = train_model(relu_kan,num_epochs)\n",
    "relu_kan_preds.append(relu_kan_results[0])\n",
    "    \n",
    "del relu_kan\n",
    "print(\" \")\n",
    "hrkan = HRKAN([2,2,1], 5, 3, -1, 1, 4)\n",
    "hrkan = hrkan.cuda()\n",
    "hrkan_results = train_model(hrkan,num_epochs)\n",
    "hrkan_preds.append(hrkan_results[0])\n",
    "del hrkan\n",
    "\n",
    "\n",
    "plot_fig(relu_kan_results, hrkan_results,bkan_results,output_folder=output_folder)\n",
    "cal_error(relu_kan_results, hrkan_results, bkan_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate mean MSE, mean MSE std. and mean training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Timing information\")\n",
    "print(\"RELU KAN\")\n",
    "print(\"{0:.5g}\".format(np.asarray(relu_kan_time)[-1]))\n",
    "print(\" \")\n",
    "print(\"HRKAN\")\n",
    "print(\"{0:.5g}\".format(np.array(hrkan_time)[-1]))\n",
    "print(\" \")\n",
    "print(\"Bayesian HRKAN\")\n",
    "print(\"{0:.5g}\".format(np.array(bkan_time)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkan_mse  = np.array((bkan_preds[0] - sol.reshape(X_test_np.shape).numpy())**2)\n",
    "hrkan_mse = np.array((hrkan_preds[0] - sol.reshape(X_test_np.shape).numpy())**2)\n",
    "rkan_mse = np.array((relu_kan_preds[0] - sol.reshape(X_test_np.shape).numpy())**2)\n",
    "bkan_mse_std = np.std((bkan_preds[0] - sol.reshape(X_test_np.shape).numpy())**2)\n",
    "hrkan_mse_std = np.std((hrkan_preds[0] - sol.reshape(X_test_np.shape).numpy())**2)\n",
    "rkan_mse_std = np.std((relu_kan_preds[0] - sol.reshape(X_test_np.shape).numpy())**2)\n",
    "    \n",
    "    \n",
    "print(\"RELU KAN\")\n",
    "print(\"Average mse: \",np.mean(rkan_mse), \"std: \",rkan_mse_std)\n",
    "print(\" \")\n",
    "print(\"HRKAN\")\n",
    "print(\"Average mse: \",np.mean(hrkan_mse), \"std: \",hrkan_mse_std)\n",
    "print(\" \")\n",
    "print(\"Bayesian HRKAN\")\n",
    "print(\"Average mse: \",np.mean(bkan_mse), \"std: \",bkan_mse_std)\n",
    "\n",
    "print(\"Average Aleatoric: \",bkan_results[-1].mean())\n",
    "print(\"Std Aleatoric: \",bkan_results[-1].std())\n",
    "print(\"Average Epistemic: \",bkan_results[-2].mean())\n",
    "print(\"Std Epistemic: \",bkan_results[-2].std())\n",
    "print(\"Average rmse: \",np.sqrt(np.average(bkan_mse)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "rapids-24.06"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
